{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcbf0b8c-e49d-406e-88dd-83f9a6d0e282",
   "metadata": {},
   "source": [
    "# Predicciones de fraudes bancarios\n",
    "Hoy vamos a predecir si transacciones de un data frame obtenido en [Kaggle](https://www.kaggle.com/datasets/dhanushnarayananr/credit-card-fraud/data) son legítimas o no. Vamos a utilizar dos modelos y ponerlos frente a frente, para así explicar sus diferencias y cuál es más efectivo y acertado en nuestra tarea. Pondremos a prueba `LogisticRegression` con `RandomForestClassifier`. ¿Cuál crees que sea más robusto para nuestra tarea?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7940e7-c900-4aff-a7da-fdff950aaf06",
   "metadata": {},
   "source": [
    "## Familiarización con los datos\n",
    "Vamos a familiarizarnos con el _dataset_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a06177f-88ca-44ea-b322-4b3c9eb891ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.877857</td>\n",
       "      <td>0.311140</td>\n",
       "      <td>1.945940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.829943</td>\n",
       "      <td>0.175592</td>\n",
       "      <td>1.294219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.091079</td>\n",
       "      <td>0.805153</td>\n",
       "      <td>0.427715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance_from_home  distance_from_last_transaction  \\\n",
       "0           57.877857                        0.311140   \n",
       "1           10.829943                        0.175592   \n",
       "2            5.091079                        0.805153   \n",
       "\n",
       "   ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "0                        1.945940              1.0        1.0   \n",
       "1                        1.294219              1.0        0.0   \n",
       "2                        0.427715              1.0        0.0   \n",
       "\n",
       "   used_pin_number  online_order  fraud  \n",
       "0              0.0           0.0    0.0  \n",
       "1              0.0           0.0    0.0  \n",
       "2              0.0           1.0    0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 8 columns):\n",
      " #   Column                          Non-Null Count    Dtype  \n",
      "---  ------                          --------------    -----  \n",
      " 0   distance_from_home              1000000 non-null  float64\n",
      " 1   distance_from_last_transaction  1000000 non-null  float64\n",
      " 2   ratio_to_median_purchase_price  1000000 non-null  float64\n",
      " 3   repeat_retailer                 1000000 non-null  float64\n",
      " 4   used_chip                       1000000 non-null  float64\n",
      " 5   used_pin_number                 1000000 non-null  float64\n",
      " 6   online_order                    1000000 non-null  float64\n",
      " 7   fraud                           1000000 non-null  float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 61.0 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('card_transdata.csv')\n",
    "display(df.head(3))\n",
    "\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ed2a85-f896-4bc2-9b61-70ca8019ab10",
   "metadata": {},
   "source": [
    "Tenemos ocho columnas y un millón de entradas. Cinco columnas son de datos binarios y tres de números decimales. Tenemos como características la distancia de la orden desde la casa del cliente, si uso un número PIN, si fue una venta en línea, la distancia desde la última transacción, etc. No hay datos nulos.\n",
    "\n",
    "Es un conjunto de datos listo para trabajar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5929a94-f8fd-4aca-a636-3dc2e1db0e20",
   "metadata": {},
   "source": [
    "## Separación de características y variable objetivo, y entrenamiento y prueba\n",
    "Como sabes, debemos trabajar con las características y la variable objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a6a56a7-5407-4b8d-a282-918547961e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('fraud', axis=1)  # Todas las columnas (características), menos la variable objetivo.\n",
    "y = df['fraud']               # La variable objetivo, la columna 'fraud'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2297d73-77dc-4ef8-96f8-428094ebb42f",
   "metadata": {},
   "source": [
    "Ahora vamos a dividir entre datos de entrenamiento y datos de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9436118d-b156-43a5-a946-63bef440d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y        \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4375f0b-6f93-49b6-8f65-5535c946546c",
   "metadata": {},
   "source": [
    "Con la información dividida, estamos listos para probar nuestro primer modelo, el cual será `LogisticRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51823b8c-9f49-4d52-b171-290af94e74b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - matriz de confusión:\n",
      "[[255484  18295]\n",
      " [  1356  24865]]\n",
      "\n",
      "Logistic Regression - reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9947    0.9332    0.9630    273779\n",
      "         1.0     0.5761    0.9483    0.7168     26221\n",
      "\n",
      "    accuracy                         0.9345    300000\n",
      "   macro avg     0.7854    0.9407    0.8399    300000\n",
      "weighted avg     0.9581    0.9345    0.9414    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "log_reg = LogisticRegression(\n",
    "    class_weight='balanced',\n",
    "    max_iter=1000,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression - matriz de confusión:\")\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n",
    "print(\"\\nLogistic Regression - reporte de clasificación:\")\n",
    "print(classification_report(y_test, y_pred_lr, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8140cbad-63eb-4c2a-aaf4-1896d4d6435d",
   "metadata": {},
   "source": [
    "El modelo de regresión logística funciona especialmente bien para la clase de fraude (1), lo cuál es el objetivo principal en un modelo como éste. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0987c71e-8f63-4342-8d3d-37fd270c6eb1",
   "metadata": {},
   "source": [
    "Ahora es turno de `RandomForestClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91c7feea-3e34-4552-be7b-ca8b89798c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - matriz de confusión:\n",
      "[[273779      0]\n",
      " [     5  26216]]\n",
      "\n",
      "Random Forest - reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000    273779\n",
      "         1.0     1.0000    0.9998    0.9999     26221\n",
      "\n",
      "    accuracy                         1.0000    300000\n",
      "   macro avg     1.0000    0.9999    0.9999    300000\n",
      "weighted avg     1.0000    1.0000    1.0000    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    class_weight='balanced_subsample'  # ayuda con el desbalance\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest - matriz de confusión:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"\\nRandom Forest - reporte de clasificación:\")\n",
    "print(classification_report(y_test, y_pred_rf, digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131dd494-87b3-43cf-9c07-cd1ae07e9734",
   "metadata": {},
   "source": [
    "El modelo _Random Forest_ funciona casi de manera perfecta. Detecta prácticamente todos los fraudes y casi nunca se equivoca marcando una transacción normal como fraude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8065a2-24a3-4405-ba2d-bc0a6cd43ae2",
   "metadata": {},
   "source": [
    "Finalmente, vamos a comparar _ROC-AUC_ de ambos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65c561cf-ca77-44a9-b58a-e0c023d35e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC Logistic Regression: 0.9795724082321173\n",
      "ROC-AUC Random Forest: 0.9999999974926029\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_proba_lr = log_reg.predict_proba(X_test)[:, 1]\n",
    "y_proba_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"ROC-AUC Logistic Regression:\", roc_auc_score(y_test, y_proba_lr))\n",
    "print(\"ROC-AUC Random Forest:\", roc_auc_score(y_test, y_proba_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5277e51e-0314-431a-90e1-e3089155d80c",
   "metadata": {},
   "source": [
    "El _Random Forest_ supera claramente a la _Logistic Regression_ y se comporta casi como un clasificador perfecto; esto refuerza lo que ya sugerían la matriz de confusión y el reporte de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeca7153-651d-43d5-8525-398237e462f3",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "El modelo de _Regresión Logística_ ofrece un desempeño sólido, pero el _Random Forest_ resulta claramente superior: logra detectar prácticamente todos los fraudes y casi no se equivoca con transacciones legítimas, con métricas cercanas a la perfección."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
